{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x73a8e15ae1a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/arxiv/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x73a8e15ae4d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/arxiv/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=971ff96f896e3b2fe4c9fd234bef1c3941b2ac45332096f93fadda851980f40f\n",
      "  Stored in directory: /home/sagaryadav/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "Requirement already satisfied: requests in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (4.13.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: transformers in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: filelock in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (75.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sagaryadav/anaconda3/envs/chatbot/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv\n",
    "!pip install requests beautifulsoup4\n",
    "!pip install huggingface_hub transformers accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages if not installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import arxiv\n",
    "from bs4 import BeautifulSoup\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# --- Free MMLM/ALLM client ---\n",
    "# Connect to a free model hosted on Huggingface\n",
    "client = InferenceClient(\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Free MMLM/ALLM client ---#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Free MMLM/ALLM client ---\n",
    "# Connect to a free model hosted on Huggingface\n",
    "client = InferenceClient(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Search Functions ---\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:\n",
    "    search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    search_results = []\n",
    "\n",
    "    for g in soup.find_all('div', class_='tF2Cxc')[:num_results]:\n",
    "        title = g.find('h3').text if g.find('h3') else \"\"\n",
    "        link = g.find('a')['href'] if g.find('a') else \"\"\n",
    "        snippet = g.find('span', class_='aCOpRe').text if g.find('span', class_='aCOpRe') else \"\"\n",
    "\n",
    "        # Fetch content\n",
    "        body = \"\"\n",
    "        try:\n",
    "            page = requests.get(link, timeout=5)\n",
    "            page_soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "            text = page_soup.get_text(separator=\" \", strip=True)\n",
    "            body = ' '.join(text.split()[:max_chars])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        search_results.append({\"title\": title, \"link\": link, \"snippet\": snippet, \"body\": body})\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "def arxiv_search(query: str, max_results: int = 2) -> list:\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "    results = []\n",
    "    for paper in search.results():\n",
    "        results.append({\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "            \"abstract\": paper.summary,\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Agents ---#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agents ---\n",
    "class GoogleSearchAgent:\n",
    "    def run(self, topic):\n",
    "        print(f\"[Google Search Agent] Searching Google for: {topic}\")\n",
    "        return google_search(topic)\n",
    "\n",
    "class ArxivSearchAgent:\n",
    "    def run(self, topic):\n",
    "        print(f\"[Arxiv Search Agent] Searching Arxiv for: {topic}\")\n",
    "        return arxiv_search(topic)\n",
    "\n",
    "class ReportAgent:\n",
    "    def run(self, topic, google_results, arxiv_results):\n",
    "        print(\"[Report Agent] Generating literature review...\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Write a detailed academic literature review on the topic: \"{topic}\". \n",
    "\n",
    "Use the following sources:\n",
    "\n",
    "Google Results:\n",
    "{google_results}\n",
    "\n",
    "Arxiv Papers:\n",
    "{arxiv_results}\n",
    "\n",
    "Make sure to:\n",
    "- Synthesize the findings\n",
    "- Summarize key points\n",
    "- Use correct references\n",
    "- Write professionally and formally\n",
    "End the review with the word TERMINATE.\n",
    "\"\"\"\n",
    "        output = client.text_generation(prompt, max_new_tokens=2000, temperature=0.7)\n",
    "        return output\n",
    "\n",
    "# --- Team Setup ---\n",
    "class LiteratureReviewTeam:\n",
    "    def __init__(self):\n",
    "        self.google_agent = GoogleSearchAgent()\n",
    "        self.arxiv_agent = ArxivSearchAgent()\n",
    "        self.report_agent = ReportAgent()\n",
    "\n",
    "    def conduct_review(self, topic):\n",
    "        google_results = self.google_agent.run(topic)\n",
    "        arxiv_results = self.arxiv_agent.run(topic)\n",
    "        report = self.report_agent.run(topic, google_results, arxiv_results)\n",
    "        return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Google Search Agent] Searching Google for: No-code platforms for building multi-agent AI systems\n",
      "[Arxiv Search Agent] Searching Arxiv for: No-code platforms for building multi-agent AI systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5668/2952236426.py:33: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for paper in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Report Agent] Generating literature review...\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.2 (Request ID: Root=1-680f9e34-7d1b118c4ed23272250c7b28;a0011258-6f41-416b-81a5-2cb03c4ba12d)\n\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo-code platforms for building multi-agent AI systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m team \u001b[38;5;241m=\u001b[39m LiteratureReviewTeam()\n\u001b[0;32m----> 6\u001b[0m review \u001b[38;5;241m=\u001b[39m \u001b[43mteam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconduct_review\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Literature Review Output ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(review)\n",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m, in \u001b[0;36mLiteratureReviewTeam.conduct_review\u001b[0;34m(self, topic)\u001b[0m\n\u001b[1;32m     45\u001b[0m google_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoogle_agent\u001b[38;5;241m.\u001b[39mrun(topic)\n\u001b[1;32m     46\u001b[0m arxiv_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marxiv_agent\u001b[38;5;241m.\u001b[39mrun(topic)\n\u001b[0;32m---> 47\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoogle_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marxiv_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mReportAgent.run\u001b[0;34m(self, topic, google_results, arxiv_results)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Report Agent] Generating literature review...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mWrite a detailed academic literature review on the topic: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\n\u001b[1;32m     18\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mEnd the review with the word TERMINATE.\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2392\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2367\u001b[0m         _set_unsupported_text_generation_kwargs(model, unused_params)\n\u001b[1;32m   2368\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_generation(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2369\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   2370\u001b[0m             details\u001b[38;5;241m=\u001b[39mdetails,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2390\u001b[0m             watermark\u001b[38;5;241m=\u001b[39mwatermark,\n\u001b[1;32m   2391\u001b[0m         )\n\u001b[0;32m-> 2392\u001b[0m     \u001b[43mraise_text_generation_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[38;5;66;03m# Parse output\u001b[39;00m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/inference/_common.py:410\u001b[0m, in \u001b[0;36mraise_text_generation_error\u001b[0;34m(http_error)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttp_error\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Otherwise, fallback to default error\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m http_error\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2362\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2362\u001b[0m     bytes_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2364\u001b[0m     match \u001b[38;5;241m=\u001b[39m MODEL_KWARGS_NOT_USED_REGEX\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:357\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.2 (Request ID: Root=1-680f9e34-7d1b118c4ed23272250c7b28;a0011258-6f41-416b-81a5-2cb03c4ba12d)\n\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "# --- Run Literature Review ---\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"No-code platforms for building multi-agent AI systems\"\n",
    "    \n",
    "    team = LiteratureReviewTeam()\n",
    "    review = team.conduct_review(topic)\n",
    "\n",
    "    print(\"\\n--- Literature Review Output ---\\n\")\n",
    "    print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not installed\n",
    "!pip install arxiv\n",
    "!pip install requests beautifulsoup4\n",
    "!pip install huggingface_hub transformers accelerate\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import arxiv\n",
    "from bs4 import BeautifulSoup\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# --- Free MMLM/ALLM client ---\n",
    "# Connect to a free model hosted on Huggingface\n",
    "client = InferenceClient(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "# --- Search Functions ---\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:\n",
    "    search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    search_results = []\n",
    "\n",
    "    for g in soup.find_all('div', class_='tF2Cxc')[:num_results]:\n",
    "        title = g.find('h3').text if g.find('h3') else \"\"\n",
    "        link = g.find('a')['href'] if g.find('a') else \"\"\n",
    "        snippet = g.find('span', class_='aCOpRe').text if g.find('span', class_='aCOpRe') else \"\"\n",
    "\n",
    "        # Fetch content\n",
    "        body = \"\"\n",
    "        try:\n",
    "            page = requests.get(link, timeout=5)\n",
    "            page_soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "            text = page_soup.get_text(separator=\" \", strip=True)\n",
    "            body = ' '.join(text.split()[:max_chars])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        search_results.append({\"title\": title, \"link\": link, \"snippet\": snippet, \"body\": body})\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "def arxiv_search(query: str, max_results: int = 2) -> list:\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "    results = []\n",
    "    for paper in search.results():\n",
    "        results.append({\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "            \"abstract\": paper.summary,\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --- Agents ---\n",
    "class GoogleSearchAgent:\n",
    "    def run(self, topic):\n",
    "        print(f\"[Google Search Agent] Searching Google for: {topic}\")\n",
    "        return google_search(topic)\n",
    "\n",
    "class ArxivSearchAgent:\n",
    "    def run(self, topic):\n",
    "        print(f\"[Arxiv Search Agent] Searching Arxiv for: {topic}\")\n",
    "        return arxiv_search(topic)\n",
    "\n",
    "class ReportAgent:\n",
    "    def run(self, topic, google_results, arxiv_results):\n",
    "        print(\"[Report Agent] Generating literature review...\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Write a detailed academic literature review on the topic: \"{topic}\". \n",
    "\n",
    "Use the following sources:\n",
    "\n",
    "Google Results:\n",
    "{google_results}\n",
    "\n",
    "Arxiv Papers:\n",
    "{arxiv_results}\n",
    "\n",
    "Make sure to:\n",
    "- Synthesize the findings\n",
    "- Summarize key points\n",
    "- Use correct references\n",
    "- Write professionally and formally\n",
    "End the review with the word TERMINATE.\n",
    "\"\"\"\n",
    "        output = client.text_generation(prompt, max_new_tokens=2000, temperature=0.7)\n",
    "        return output\n",
    "\n",
    "# --- Team Setup ---\n",
    "class LiteratureReviewTeam:\n",
    "    def __init__(self):\n",
    "        self.google_agent = GoogleSearchAgent()\n",
    "        self.arxiv_agent = ArxivSearchAgent()\n",
    "        self.report_agent = ReportAgent()\n",
    "\n",
    "    def conduct_review(self, topic):\n",
    "        google_results = self.google_agent.run(topic)\n",
    "        arxiv_results = self.arxiv_agent.run(topic)\n",
    "        report = self.report_agent.run(topic, google_results, arxiv_results)\n",
    "        return report\n",
    "\n",
    "# --- Run Literature Review ---\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"No-code platforms for building multi-agent AI systems\"\n",
    "    \n",
    "    team = LiteratureReviewTeam()\n",
    "    review = team.conduct_review(topic)\n",
    "\n",
    "    print(\"\\n--- Literature Review Output ---\\n\")\n",
    "    print(review)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
